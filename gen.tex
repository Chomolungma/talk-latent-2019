
\begin{frame}{ Outline}
  \begin{itemize}
  \item \textcolor{gray}{Background: Core Model and Implementation}
    \air
  \item \textbf{Work 1: Generation (\textit{Learning Neural Templates})}
    \air

  \item \textcolor{gray}{Work 2: Attention}
    \air


  \item \textcolor{gray}{Challenges: Text Generation and Deep Learning}
  \end{itemize}

  \begin{center}
    \textbf{Can we learn to control text generation systems?}
  \end{center}

\end{frame}




% \begin{frame}{Part 4: Deep Latent-Variable Mdoels}

%    \begin{center}
%   \begin{tikzpicture}
%     \node[rounded corners, thick, draw] (ana) at (-15mm, 15mm) {Analysis};
%     \node[rounded corners, thick, fill=yellow,  draw] (meth) at (0mm, 30mm) {\ Methods\phantom{p}};
%     \node[rounded corners, thick, draw] (app) at (25mm, 30mm) {Applications};
%     \node[rounded corners, thick, fill=yellow, draw] (und) at (35mm, 15mm) {Understanding};
%     \node[rounded corners, thick, draw] (dep) at (25mm, 0mm){Scaling};
%     \node[rounded corners, thick, draw] (imp) at (0, 0) {Open-Source};
%     \draw (ana) -- (meth) --(app) -- (und) -- (dep) -- (imp) -- (ana);
%   \end{tikzpicture}
%   \end{center}
% \end{frame}


\begin{frame}{Talk about Data}
  \vspace{-1cm}
  \begin{center}
    \begin{tikzpicture}

      \node (gal) {\includegraphics[width=1.5cm]{phone}};
      \node [rounded corners, above =(0.2cm) of gal] {$p_\theta$};
      \node (a) [rectangle, yshift=1cm, xshift=-5cm, scale=0.7, draw,thick,fill=blue!0,text width=11em, rounded corners, inner sep =5pt, minimum height=1em] {
        \small
        \begin{tabular}[]{lc}
          \textbf{Fitzbillies} & \\
          \toprule
          type & coffee shop \\
          price & $<$ \pounds 20 \\
          food & Chinese \\
          rating  & 3/5 \\
          area & city centre \\
          \bottomrule
        \end{tabular}};



      % \path<2>[draw, ->] (a) --  (a -|  gal.west) ;


      \node [rounded corners, left =(0.2cm) of a] {\alert<1>{$x$}};
      \path[draw, ->] (a) --  (gal.west);
%       \visible<2->{
%         \node(b) [xshift=-5cm, yshift=-2.5cm, rectangle, scale=0.7, draw,thick,fill=blue!0,text width=18em, rounded corners, inner sep =5pt, minimum height=1em]{\baselineskip=50pt \small
% $\textcolor{gray}{|} $ $ \substack{\text{The \rule{15pt}{1pt}}\\\text{\rule{15pt}{1pt}}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \substack{\text{is a}\\\text{is an}\\\text{is an expensive}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt}} \ \textcolor{gray}{|} \  $ $ \substack{\text{providing}\\\text{serving}\\\text{offering}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt}} \ \textcolor{gray}{|} \  $ $ \substack{\text{food}\\\text{cuisine}\\\text{foods}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{in the} \ \textcolor{gray}{|} \  $ $ \substack{\text{high}\\\text{moderate}\\\text{less than average}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \substack{\text{price}\\\text{price range}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{.}$ $\textcolor{gray}{|}$ $ \text{It is} \ \textcolor{gray}{|} \  $ $ \substack{\text{located in the}\\\text{located near}\\\text{near}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt}} \ \textcolor{gray}{|} \  $ $ \text{.}$ $ \textcolor{gray}{|} \  $ $ \substack{\text{Its customer rating is}\\\text{Their customer rating is}\\\text{Customers have rated it}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt} out of \rule{15pt}{1pt}} \ \textcolor{gray}{|} \  .$
%           \par};

%         \node [rounded corners, above = (0.1cm) of b] {$z_{1:T}$};
%         \path[draw, ->] (b) --  (gal.west);
%       }

      \visible<2->{
        \node(c) [xshift=4.5cm, rectangle, scale=0.75, draw,thick,fill=blue!0,text width=20em, rounded corners, inner sep =5pt, minimum height=1em] {\baselineskip=50pt \small \large Fitzbillies   is a     coffee shop   providing   Chinese food  in the   moderate  price range .  It is   located in the city centre  .  Its customer rating is  3 out of 5 . \par };
      \node [rounded corners, above = (0.1cm) of c] { $y_{1:T}$};
      \path[draw, ->] (gal.east) -- (c);
    }


    \end{tikzpicture}
  \end{center}
\end{frame}


\begin{frame}{Talking About Data}
  \begin{center}
    \mair
    \mair


    \begin{tikzpicture}

      \node (gal) {\includegraphics[width=1.5cm]{phone}};
      \node [rounded corners, above =(0.2cm) of gal] {$p_\theta$};


      \node (a) [rectangle, yshift=2cm, xshift=-4.5cm, scale=0.8, draw,thick,fill=blue!0,text width=11.5em, rounded corners, inner sep =5pt, minimum height=1em] {\centering
        \includegraphics[width=4.5cm]{wiki}};
      \path[draw, ->] (a) --  (gal.west) ;


      \node [rounded corners, left =(0.2cm) of a] {{$x$}};

      \visible<4 - >{
        \node(b) [xshift=-4.3cm, yshift=-1.5cm, rectangle, scale=0.7, draw,thick,fill=blue!0,text width=15em, rounded corners, inner sep =5pt, minimum height=1em]{\baselineskip=50pt \large
 \rule{15pt}{1pt} (born \rule{15pt}{1pt}) was a
\rule{15pt}{1pt} \rule{15pt}{1pt} , who
lived in the \rule{15pt}{1pt} . He was
known for contributions to \rule{15pt}{1pt} .
          \par};

        \node [rounded corners, left = (0.1cm) of b] {$z_{1:T}$};
        \path[draw, ->] (b) --  (gal.west);
      }


      \visible<2>{
        \node(b) [xshift=4.3cm, yshift=-0cm, rectangle, scale=0.8, draw,thick,fill=blue!0,text width=15em, rounded corners, inner sep =5pt, minimum height=1em]{\baselineskip=50pt \large
          Frederick Parker-Rhodes
(21 November 1914 - 2
March 1987) was an
English linguist, plant
pathologist, computer
scientist, mathematician,
mystic, and mycologist.
          \par};

        \node [rounded corners, above = (0.2cm) of b] {$y_{1:T}$};
        \path[draw, <-] (b) --  (b -| gal.east) ;
      }

      \visible<3>{
        \node(b) [xshift=4.3cm, yshift=-0cm, rectangle, scale=0.8, draw,thick,fill=blue!0,text width=15em, rounded corners, inner sep =5pt, minimum height=1em]{\baselineskip=50pt \large
          Frederick Parker-Rhodes (21 November
1914 - 2 March 1987) was an English
mycology and \alert{plant pathology,
mathematics at the University of UK}.
          \par};

        \node [rounded corners, above = (0.2cm) of b] {$y^*_{1:T}$};
        \path[draw, <-] (b) --  (b -| gal.east) ;
      }

      \visible<5>{
        \node(b) [xshift=4.5cm, yshift=-0cm, rectangle, scale=0.8, draw,thick,fill=blue!0,text width=12em, rounded corners, inner sep =5pt, minimum height=1em]{\baselineskip=50pt \large
          \underline{Frederick Parker-Rhodes} (born \underline{21 November 1914}) was a \underline{English
mycologist} who
lived in the \underline{UK}. He was
known for contributions to \underline{plant pathology}.
          \par};

        \node [rounded corners, above = (0.2cm) of b] {$y^*_{1:T}$};
        \path[draw, <-] (b) --  (b -| gal.east) ;
      }



    \end{tikzpicture}
  \end{center}
\end{frame}


% \begin{frame}{Alternative Approach: Templated Generation}
%   \begin{center}
%     \begin{tikzpicture}

%       \node (gal) {\includegraphics[width=1.5cm]{phone}};
%       \node [rounded corners, above =(0.2cm) of gal] {$\theta$};


%       \node (a) [rectangle, yshift=1cm, xshift=-5cm, scale=0.8, draw,thick,fill=blue!0,text width=13em, rounded corners, inner sep =5pt, minimum height=1em] {
%         \includegraphics[width=5cm]{wiki}};
%       \path[draw, ->] (a) --  (a -|  gal.west) ;


%       \node [rounded corners, above =(0.2cm) of a] {{$x$}};

%       \visible{
%         \node(b) [xshift=4.5cm, yshift=-1cm, rectangle, scale=0.8, draw,thick,fill=blue!0,text width=12em, rounded corners, inner sep =5pt, minimum height=1em]{\baselineskip=50pt \small
%           [name] (born [born]) was a
% [nationality] [occupation], who
% lived in the [residence]. He was
% known for contributions to [known\_for].

%           \par};

%         \node [rounded corners, above = (0.2cm) of b] {$y_{1:T}$};
%         \path[draw, <-] (b) --  (b -| gal.east) ;
%       }




%     \end{tikzpicture}
%   \end{center}

% \end{frame}


\begin{frame}{Arguments for Templated Generation}
Guarantees about the quality, in particular,
\air


\begin{itemize}
\item \textbf{Interpretable} in its factual content.
  \air


  \air

\item \textbf{Controllable} in terms of style.
  \air


\end{itemize}

\begin{center}
  Can we achieve these criteria within a deep learning system?
\end{center}
\pause


\end{frame}


\begin{frame}{Deep Latent-Variable Models}

\textbf{Strategy:} Learn a probabilistic model and \textit{extract} template-like constraints.

\air

  Expose specific choices as latent variables $z$.

\[ p(y, z\ |\ x \param \theta)\]

\begin{itemize}
    \item $x, y$ as before, \textit{what to talk about, how to say it}
    \item $z$ is a collection of problem-specific latent variables, \textit{why we said it that way}
\end{itemize}

\pause
\textbf{Challenge:} Combine with deep learning approach, $\theta$.

% \begin{itemize}
%     \item Data consists of $N$ i.i.d samples,
% \end{itemize}

%                 \[ p(x^{(1:N)}, z^{(1:N)} \param \theta ) = \prod_{n=1}^N p(x^{(n)} \given z^{(n)}; \theta) p(z^{(n)};\theta). \]

\end{frame}

\begin{frame}{Motivating Example: Deep Clustering}

% \[p(x, z \param \theta)
%       = \mu_{z} \times  \prod_{t=1}^T \softmax(\RNN(\boldh_{t-1}, x_t\param \pi_z))\]
\begin{center}

\begin{tikzpicture}
  %\tikz{
% nodes
\node (dots) {$\ldots$};%
 \node[obs, left=1cm of dots] (x1) {$y_1$};%
 \node[obs, right=1cm of dots] (xT) {$y_T$};%
 \node[latent, above=of dots, fill=red!20] (z) {$z$}; %
 \node[const, above=(0.5cm) of z] (mu) {$$};
 % \node[const, below left=0.3cm and 0.8cm of x1] (pi) {$\pi$};

% plate
 % \plate {plate1} {(dots)(x1)(xT)(z)} {$N$}; %
% edges
 \edge {z} {dots};
 \edge {z} {x1};
 \edge {z} {xT};
 % \edge {mu} {z};
 % \edge {pi.east} {x1,xT.south};
 \edge {x1} {dots};
 %\edge[bend left] {x1.south} {xT.south};
  \edge {dots} {xT};

 \draw[->]
 (x1) edge[bend right=10] node [right] {} (xT);
 %}
 \node(a) [right=(3cm) of mu, fill=red!20]{The film is the first from ... };
 \node (aa) [right=(0.2cm) of a]{$z=1$};
 \node(b)[below = of a, fill=blue!20]{Allen shot four-for-nine ... };
 \node (bb) [below= of aa]{$z=2$};
 \node(c) [below = of b, fill=orange!20]{In the last poll Ericson led ...};
 \node (cc) [below=of bb]{$z=3$};
 \end{tikzpicture}
 %}
\end{center}
%\begin{align*}
%\boldh_{z,t} &= \tanh(\mathbf{W}_z \bolde_t +\mathbf{U}_z\boldh_{z,t-1}  + \boldb_{z}) \nonumber \\
%p(x_{t} \given x_{<t} , z) &= \softmax(\mathbf{V} \boldh_{z,t-1} + \boldc)_{x_{t}} \nonumber \\
%p(x_1, \ldots, x_T \given z) &= \prod_{t=1}^{T} p(x_{t} \given x_{<t} , z)
%\end{align*}
\begin{enumerate}
\item Draw cluster $z \in \{1, \ldots, Z\}$.
\item Draw word sequence $y_{1:T}$ from decoder RNN $z$.
\end{enumerate}
% \[p(y, z\ |\  x \param \theta)
%        = \mu_{z} \times   \RNN(y_{1:T} \param \pi_z) \]
\pause

% \textbf{Training:} Learning RNN $\theta$ requires inner-step of posterior inference on $z$.

\end{frame}


% begin{frame}
% \begin{center}
%     \textbf{ Latent-Variable Model Basics }
%   \end{center}


% \begin{align*}
% p(x, z \param \theta).
% \end{align*}

% \pause
% \begin{itemize}
%     \item $x$ is our observed data
%     \item $z$ is a collection of latent variables
%     \item $\theta$ are the deterministic parameters of the model, such as the neural network parameters
% \end{itemize}

% \pause

% \begin{itemize}
%     \item Data consists of $N$ i.i.d samples,
% \end{itemize}


%                 \[ p(x^{(1:N)}, z^{(1:N)} \param \theta ) = \prod_{n=1}^N p(x^{(n)} \given z^{(n)}; \theta) p(z^{(n)};\theta). \]
% \end{frame}

% \begin{frame}{Posterior Inference}
%     We'll be interested in the \textit{posterior} over latent variables $z$:

%     \begin{align*}
%         p(z \given y, x \param \theta) = \frac{\displaystyle p(y, z | x  \param \theta)}{\displaystyle p(y | x  \param \theta)} = \frac{\displaystyle p(y\given x, z \param  \theta) p(z | x  \param  \theta)}{\displaystyle \sum_{z'} p(y \given x, z'\param  \theta) p(z'| x\param  \theta) }.
%     \end{align*}

%     \air

%     \pause
%     % Why?
%     % \begin{itemize}
%     %   \item Required for training
%     %   \item Latent $z$ gives separation of data.

% % \item Intuition: if I know likely $z^{(n)}$ for $x^{(n)}$, I can learn by maximizing $p(x^{(n)} \given z^{(n)} \param \theta)$.
%         % \begin{itemize}
%         %     \item Intuition: if I know likely $z^{(n)}$ for $x^{(n)}$, I can learn by maximizing $p(x^{(n)} \given z^{(n)} \param \theta)$.
%         % \end{itemize}
%     % \end{itemize}

%     How?

%     \begin{itemize}
%     \item Sum out over all discrete choices (e.g. run $K$ RNNs).
%     \item Variational inference based methods.
%     \end{itemize}

% \end{frame}


% \begin{frame}{Preliminary Model 2: Copy Model}
% %{(Gu et al, 2016) (Gulcehre et al, 2016)}

% Generative process:
% \begin{enumerate}
% \item Draw copy switch $z_t \in \{0, 1\}$ from a Bernoulli.
% \item Draw words $y_t$ wherre
% \begin{itemize}
% \item If $z = 0$, generate a new word from the decoder.
%   \air
% \item If $z = 1$, copy a word from the source data.
% \end{itemize}

% \end{enumerate}

% \air
% \air

% Example:
% \begin{center}
% \underline{Frederick Parker-Rhodes} (born \underline{21 November
% 1914}) was a English \underline{linguist} $\ldots$


% % \centerline{\small (See et al, 2017)}
% \end{center}
% \end{frame}


\begin{frame}{Time-Series Clustering}

  Similar approach can be employed with other probabilistic models.
  \air

  \textbf{Hidden Semi-Markov Model}
  \begin{itemize}

  \item Each discrete cluster produces multiple emissions (e.g. phrases).

  \item Parameterized with \textit{transition}
      and \textit{emission} distributions.
      \air

  \end{itemize}

  \begin{figure}
    \centering
    \begin{tikzpicture}[node distance=0.6cm]
    % \draw [step=0.2cm,gray,very thin] (-1.11, -1.11) grid  (1.1, 1.11);
    \node [circle](x){$$} ;
    \node[circle, draw, above right=of x, xshift = 1cm, fill=red!20](z){$z_1$};
    \node[ draw, rounded corners, below=of z, fill=red!10](rnn){};
    \node[circle, draw, below= of rnn](y){$y_1$};
    \node[circle, draw, right= of y](ya){$y_2$};
    \node[circle, draw, right= of ya](yb){$y_3$};
    \node[circle, draw, right= of yb](yc){$y_4$};
    \node[draw, rounded corners,  above= of yc, fill=blue!10](rnnb){};
    \node[circle, draw, above= of rnnb, fill=blue!20](zb){$z_{4}$};
    \draw[-] (z) -- (rnn) -- (y);
    \draw[-]  (rnn) -- (ya);
    \draw[-] (rnn) -- (yb);

    \draw[-] (zb) -- (rnnb) -- (yc);
     \draw (z) --node(mlp)[fill=white, draw, rounded corners]{} (zb);
     % \draw (x.north) edge [bend left=40] (mlp);
     % \draw (x) edge[] (rnn);
     % \draw (x) edge[bend left=20] (rnnb);

    \end{tikzpicture}
  \end{figure}

\end{frame}


\begin{frame}{Model: A Deep Hidden Semi-Markov Model}

  % \item Employ HSMM as a conditional latent variable language model, $p(y_1, \ldots, y_T, z\ |\ x)$.
  % \item Transition Distribution: neural network between clusters.

  Distribution: Encoder-Decoder, specialized per cluster $\{1, \ldots, Z\}$.

  \begin{center}

      \begin{figure}
        \centering
        \scalebox{0.8}{
        \begin{tikzpicture}[node distance=0.6cm]
          \draw [step=0.2cm,gray,very thin] (-1.11, -1.11) grid  (1.1, 1.11);
          \node [draw, circle, fill=black!10](x){$x$} ;
          \node[circle, draw, above right=of x, xshift = 1cm, fill=red!20](z){$z_1$};
          \node[ draw, rounded corners, below=of z, fill=red!10](rnn){Decoder};
          \node[circle, draw, below= of rnn](y){$y_1$};
          \node[circle, draw, right= of y](ya){$y_2$};
          \node[circle, draw, right= of ya](yb){$y_3$};
          \node[circle, draw, right= of yb](yc){$y_4$};
          \node[draw, rounded corners,  above= of yc, fill=blue!10](rnnb){Decoder};
          \node[circle, draw, above= of rnnb, fill=blue!20](zb){$z_{4}$};
          \draw[-] (z) -- (rnn) -- (y);
          \draw[-]  (rnn) -- (ya);
          \draw[-] (rnn) -- (yb);

          \draw[-] (zb) -- (rnnb) -- (yc);
          \draw (z) --node(mlp)[fill=white, draw, rounded corners]{T} (zb);
          \draw (x.north) edge [bend left=40] (mlp);
          \draw (x) edge[] (rnn);
          \draw (x) edge[bend left=20] (rnnb);

        \end{tikzpicture}
      }
        % \caption{HSMM factor graph (under a fixed segmentation) to illustrate parameters. Here we assume $z_1$ is in the ``red'' state (out of $K$ possibilities), and transitions to the ``blue'' state after emitting three words. The transition model, shown as $T$, is a function of the two states and the neural encoded source $x$. The emission model is a function of a ``red'' RNN model (with copy attention over $x$) that generates words 1, 2 and 3. After transitioning, the next word $y_4$ is generated by the ``blue'' RNN, but independently of the previous words.}
        \label{fig:my_label}
      \end{figure}

  \end{center}

  \pause

  \begin{center}
    \textbf{Probabilistic Model $\Rightarrow$ Templates}

    (Step 1) Train  (Step 2) Match   (Step 3) Extract
  \end{center}
\end{frame}

\begin{frame}{Step 1: Training HSMM}

  Training requires summing over clusters and segmentation of deep model.
    \[ {\cal L}(\theta) =\log \E_{z_{1:T}} p(\hat{y}_{1:T} \ | z_{1:T}, \ x; \theta)  = \log \sum_{z_{1:T}} p(\hat{y}_{1:T}, z_{1:T} \ |\ x; \theta)\]
    \pause
    \centerline{\textbf{Example}}

    \begin{center}


$\hat{y}_{1:T} =$ Frederick Parker-Rhodes  was an English linguist, plant pathologist $\ldots$
      \[\Downarrow \sum_{z_{1:T}} p(\hat{y}_{1:T}, z_{1:T} \ |\ x; \theta)\]
\colorbox{green}{Frederick Parker-Rhodes}  \colorbox{red}{was an English} \colorbox{skyblue}{linguist}, \colorbox{redpurple}{plant pathologist} $\ldots$\\ \pause
\colorbox{red}{Frederick} \colorbox{redpurple}{Parker-Rhodes}  \colorbox{red}{was an\phantom{D}} \colorbox{skyblue}{English linguist}, \colorbox{green}{plant pathologist} $\ldots$\\ \pause
\colorbox{redpurple}{Frederick}  \colorbox{orange}{Parker-Rhodes was an English linguist ,} \colorbox{skyblue}{linguist}, \colorbox{redpurple}{plant pathologist} $\ldots$
    \end{center}
\end{frame}

\begin{frame}{Step 1: Technical Methodology}

  Training is end-to-end, i.e. clusters and segmentation are learned
  simultaneously with encoder-decoder model on GPU.

  \begin{itemize}
  \item  Backpropagation through dynamic programming.
  \item Parameters are trained by exactly marginalizing over segmentations.
  \item Utilize HSMM backward algorithm within standard training.
  \end{itemize}

\end{frame}
% \begin{frame}{Technical Methodology}
%     \begin{itemize}
%     \item Requires summing over all clusters and segmentation.
%     \item Approach: backprop through HSMM dynamic programming algorithm, exact gradient.
%     \item Gives a new definition for $f_\theta(y_{1:T}, x)$
%     \end{itemize}
% \end{frame}


\begin{frame}{Step 2: Template Matching}
  Finding best cluster sequences for each  training sentence.
  \begin{figure}
    \centering
    \scalebox{0.5}{
    \begin{tikzpicture}[node distance=0.6cm]
    \draw [step=0.2cm,gray,very thin] (-1.11, -1.11) grid  (1.1, 1.11);
    \node [draw, circle, fill=black!10](x){$x$} ;
    \node[circle, draw, above right=of x, xshift = 1cm, fill=red!20](z){$z_1$};
    \node[ draw, rounded corners, below=of z, fill=red!10](rnn){Decoder};
    \node[circle, draw, below= of rnn](y){$y_1$};
    \node[circle, draw, right= of y](ya){$y_2$};
    \node[circle, draw, right= of ya](yb){$y_3$};
    \node[circle, draw, right= of yb](yc){$y_4$};
    \node[draw, rounded corners,  above= of yc, fill=blue!10](rnnb){Decoder};
    \node[circle, draw, above= of rnnb, fill=blue!20](zb){$z_{4}$};
    \draw[-] (z) -- (rnn) -- (y);
    \draw[-]  (rnn) -- (ya);
    \draw[-] (rnn) -- (yb);

    \draw[-] (zb) -- (rnnb) -- (yc);
     \draw (z) --node(mlp)[fill=white, draw, rounded corners]{T} (zb);
     \draw (x.north) edge [bend left=40] (mlp);
     \draw (x) edge[] (rnn);
     \draw (x) edge[bend left=20] (rnnb);
    \end{tikzpicture}
}
    % \caption{HSMM factor graph (under a fixed segmentation) to illustrate parameters. Here we assume $z_1$ is in the ``red'' state (out of $K$ possibilities), and transitions to the ``blue'' state after emitting three words. The transition model, shown as $T$, is a function of the two states and the neural encoded source $x$. The emission model is a function of a ``red'' RNN model (with copy attention over $x$) that generates words 1, 2 and 3. After transitioning, the next word $y_4$ is generated by the ``blue'' RNN, but independently of the previous words.}
  \end{figure}
    \[ z_{1:T}^* = \argmax_{z_{1:T}} p(y_{1:T}, z_{1:T} \ |\ x; \theta)\]
    \pause
    \centerline{\textbf{Example}}
    \begin{center}


Frederick Parker-Rhodes  was an English linguist, plant pathologist
    \begin{center}
      $\Downarrow \argmax_{z_{1:T}}$
    \end{center}
\colorbox{green}{Frederick Parker-Rhodes}  \colorbox{red}{was an English} \colorbox{skyblue}{linguist}, \colorbox{redpurple}{plant pathologist} $\ldots$\\ \pause
    \end{center}
\end{frame}

\begin{frame}{Step 3: Template Extraction}
  Find identical cluster sequences $z_{1:T}$ that occur most often.
\air
\begin{center}


Frederick Parker-Rhodes  was an English linguist, plant pathologist $\ldots$ \\
Bill Jones  was an American professor, and well-known author $\ldots$\\
$\vdots$
\begin{center}
      $\Downarrow \argmax_{z_{1:T}}$
    \end{center}
\colorbox{green}{Frederick Parker-Rhodes}  \colorbox{red}{was an English} \colorbox{skyblue}{linguist}, \colorbox{redpurple}{plant pathologist} $\ldots$\\
\colorbox{green}{Bill Jones}  \colorbox{red}{was an American} \colorbox{skyblue}{professor}, \colorbox{redpurple}{and well-known author} $\ldots$\\
$\vdots$
\end{center}

\end{frame}




\begin{frame}{Example Templates: Wikipedia}

  Example common extracted ``templates''.

  \begin{center}
    \includegraphics[trim={3cm 4.5cm 0.2cm 0cm}, clip, width=0.9\textwidth]{extemp}
  \end{center}
\end{frame}



% \begin{frame}{Technical Methodology}

%   Training is end-to-end, i.e. clusters and segmentation are learned
%   simultaneously with encoder-decoder model on GPU.


%   \begin{itemize}
%   \item  Training Technique: Backpropagation through dynamic programming. Parameters are trained by exactly marginalizing over segmentations (HSMM backward algorithms)
%   \end{itemize}
%   \air

%   \begin{itemize}
%   \item Extraction Technique: Viterbi algorithm over encoder-decoder potentials.
%   \end{itemize}


% \end{frame}






% \begin{frame}{ Latent Variable Models for Generation}
%   \textbf{Ongoing Work:} Can we develop other discrete latent-variable models for generation?

%   \air

%   \textbf{Goals:}

%     \begin{itemize}
%     \item Model Control
%     \item Model Debugging
%     \item Model Uncertainty
%     \end{itemize}
% \end{frame}




% \begin{frame}
%   \begin{figure}
%     \centering

%     \footnotesize
% \begin{tabular}{@{}ll@{}}
% \toprule
% \bf Meaning Representation        & \begin{tabular}[c]{@{}l@{}}name{[}The Golden Palace{]},  eatType{[}coffee shop{]},  food{[}Fast food{]}, \\ priceRange{[}cheap{]},  customer rating{[}5 out of 5{]},  area{[}riverside{]}\end{tabular}         \\ \midrule
% \bf Reference & \begin{tabular}[c]{@{}l@{}}A coffee shop located on the riverside  called The Golden Palace,  \\ has a 5 out of 5 customer rating.  Its price range are fairly cheap  \\for its excellent Fast food.\end{tabular} \\ \bottomrule
% \end{tabular}
%   \end{figure}

% \end{frame}

% \begin{frame}{Standard Approach}


% \textbf{Step 1: Encode the Source}
% \air

% \begin{small}
% Fitzbillies,type[coffee shop],price[$<$ \pounds 20],food[Chinese],rate[3/5],area[city centre]
% \end{small}

% \vspace{0.3cm}

% \textbf{Step 2: Generate with RNN Decoder}

% \air

% \underline{Fitzbillies}  is a  \underline{coffee shop}  providing  \underline{Chinese} food in the  moderate  price range  .  It is  located in the  \underline{city centre}  .  Its customer rating is  \underline{3} out of \underline{5}.

% \end{frame}

% \begin{frame}{Issues}
% \begin{enumerate}
% \item Interpretable in its content selection?
%   \air

%   \textit{Decisions may come from anywhere in the source $x$.}

%   \air

% \item Controllable in terms of style and form?
%   \air

%   \textit{Rely on a learned system to determine content.}
% \end{enumerate}

%\end{frame}

\begin{frame}{Neural Template Generation Approach}
  \vspace{-1cm}
  \begin{center}
    \begin{tikzpicture}

      \node (gal) {\includegraphics[width=1.5cm]{phone}};
      \node [rounded corners, above =(0.2cm) of gal] {$p_\theta$};
      \node (a) [rectangle, yshift=1cm, xshift=-5cm, scale=0.7, draw,thick,fill=blue!0,text width=11em, rounded corners, inner sep =5pt, minimum height=1em] {
        \small
        \begin{tabular}[]{lc}
          \textbf{Fitzbillies} & \\
          \toprule
          type & [coffee shop] \\
          price & $<$ \pounds 20 \\
          food & Chinese \\
          rating  & 3/5 \\
          area & city centre] \\
          \bottomrule
        \end{tabular}};



      % \path<2>[draw, ->] (a) --  (a -|  gal.west) ;


      \node [rounded corners, above =(0.2cm) of a] {\alert<1>{$x$}};
      \path[draw, ->] (a) --  (gal.west);
      \visible<2->{
        \node(b) [xshift=-5cm, yshift=-2.5cm, rectangle, scale=0.7, draw,thick,fill=blue!0,text width=18em, rounded corners, inner sep =5pt, minimum height=1em]{\baselineskip=50pt \small
$\textcolor{gray}{|} $ $ \substack{\text{The \rule{15pt}{1pt}}\\\text{\rule{15pt}{1pt}}\\ \dots}
\ \textcolor{gray}{|} \  $ $ \substack{\text{is a}\\\text{is an}\\\text{is an expensive}\\ \dots}
\ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt}} \ \textcolor{gray}{|} \  $ $ \substack{\text{providing}\\\text{serving}\\\text{offering}\\ \dots}
\ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt}} \ \textcolor{gray}{|} \  $ $ \substack{\text{food}\\\text{cuisine}\\\text{foods}\\ \dots}
\ \textcolor{gray}{|} \  $ $ \text{in the} \ \textcolor{gray}{|} \  $ $ \substack{\text{high}\\\text{moderate}\\\text{less than average}\\ \dots}
\ \textcolor{gray}{|} \  $ $ \substack{\text{price}\\\text{price range}\\ \dots}
\ \textcolor{gray}{|} \  $ $ \text{.}$ $\textcolor{gray}{|}$ $ \text{It is} \ \textcolor{gray}{|} \  $ $ \substack{\text{located in the}\\\text{located near}\\\text{near}\\ \dots}
\ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt}} \ \textcolor{gray}{|} \  $ $ \text{.}$ $ \textcolor{gray}{|} \  $ $ \substack{\text{Its customer rating is}\\\text{Their customer rating is}\\\text{Customers have rated it}\\ \dots}
\ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt} out of \rule{15pt}{1pt}} \ \textcolor{gray}{|} \  .$
          \par};

        \node [rounded corners, above = (0.1cm) of b] {$z_{1:T}$};
        \path[draw, ->] (b) --  (gal.west);
      }

      \visible<3->{
        \node(c) [xshift=4.5cm, rectangle, scale=0.75, draw,thick,fill=blue!0,text width=20em, rounded corners, inner sep =5pt, minimum height=1em] {\baselineskip=50pt \small $\|$  Fitzbillies $\|$   is a $\|$    coffee shop $\|$   providing $\|$  Chinese $\|$ food $\|$ in the $\|$  moderate $\|$ price range $\|$ . $\|$ It is  $\|$ located in the $\|$ city centre $\|$ . $\|$ Its customer rating is $\|$ 3 out of 5 $\|$ . \par };
      \node [rounded corners, above = (0.1cm) of c] { $y_{1:T}$};
      \path[draw, ->] (gal.east) -- (c);
    }


    \end{tikzpicture}
  \end{center}
\end{frame}

% \textbf{Step 1: Encode the Source}

% \begin{small}
% Fitzbillies,ty[coffee shop],pr[$<$ \pounds 20],food[Chinese],cust[3/5],area[city centre]
% \end{small}

% \pause
% \air
% \textbf{Step 2: Select a \textit{Template}}

%     \begin{center}

% $\textcolor{gray}{|} $ $ \substack{\text{The \rule{15pt}{1pt}}\\\text{\rule{15pt}{1pt}}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \substack{\text{is a}\\\text{is an}\\\text{is an expensive}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt}} \ \textcolor{gray}{|} \  $ $ \substack{\text{providing}\\\text{serving}\\\text{offering}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt}} \ \textcolor{gray}{|} \  $ $ \substack{\text{food}\\\text{cuisine}\\\text{foods}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{in the} \ \textcolor{gray}{|} \  $ $ \substack{\text{high}\\\text{moderate}\\\text{less than average}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \substack{\text{price}\\\text{price range}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{.}$ $\textcolor{gray}{|}$ $ \text{It is} \ \textcolor{gray}{|} \  $ $ \substack{\text{located in the}\\\text{located near}\\\text{near}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt}} \ \textcolor{gray}{|} \  $ $ \text{.}$ $ \textcolor{gray}{|} \  $ $ \substack{\text{Its customer rating is}\\\text{Their customer rating is}\\\text{Customers have rated it}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt} out of \rule{15pt}{1pt}} \ \textcolor{gray}{|} \  .$
%     \end{center}
% \pause
% \air
% \textbf{Step 3: Fill-in Each Segment}
%     \air


% $\|$ \underline{Fitzbillies} $\|$  \pause is a $\|$ \pause   \underline{coffee shop} $\|$ \pause  providing $\|$  \underline{Chinese} $\|$ food $\|$ in the $\|$  moderate $\|$ price range $\|$ . $\|$ It is  $\|$ located in the $\|$ \underline{city centre} $\|$ . $\|$


    % \caption{An example from the E2E Generation dataset~\citep{novikova2017e2e}; knowledge base $x$ (top) contains 5 records, and $\hat{y}$ (middle) is a system generation; records are shown as \texttt{type[value]}.
    % (bottom) An induced neural template learned by the system and employed in generating $\hat{y}$. %Each cell shows the possible output choices and each underscore represents a slot fillable with copy attention.
    % Each cell represents a segment in the learned segmentation, and underscores show where slots are (typically) filled through copy attention during generation.
    % }

% \end{frame}


% \begin{frame}{Criteria}

% \begin{enumerate}
% \item Interpretable in its content selection.
%   \air

%   \textit{Decisions are localized to a segment of the template.}

%   \air

% \item Easily controllable in terms of style and form.
%   \air

%   \textit{Alternative realizations through different templates.}
% \end{enumerate}


% \air

% \pause



% \alert{However:} templates feel much less ``end-to-end''.
% How can we learn them from data?

% \end{frame}



% \begin{frame}{Neural Template}
% \air

%       \begin{center}

% $\textcolor{gray}{|} $ $ \substack{\text{The \rule{15pt}{1pt}}\\\text{\rule{15pt}{1pt}}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \substack{\text{is a}\\\text{is an}\\\text{is an expensive}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt}} \ \textcolor{gray}{|} \  $ $ \substack{\text{providing}\\\text{serving}\\\text{offering}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt}} \ \textcolor{gray}{|} \  $ $ \substack{\text{food}\\\text{cuisine}\\\text{foods}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{in the} \ \textcolor{gray}{|} \  $ $ \substack{\text{high}\\\text{moderate}\\\text{less than average}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \substack{\text{price}\\\text{price range}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{.}$ $\textcolor{gray}{|}$ $ \text{It is} \ \textcolor{gray}{|} \  $ $ \substack{\text{located in the}\\\text{located near}\\\text{near}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt}} \ \textcolor{gray}{|} \  $ $ \text{.}$ $ \textcolor{gray}{|} \  $ $ \substack{\text{Its customer rating is}\\\text{Their customer rating is}\\\text{Customers have rated it}\\ \dots}
% \ \textcolor{gray}{|} \  $ $ \text{\rule{15pt}{1pt} out of \rule{15pt}{1pt}} \ \textcolor{gray}{|} \  .$
%     \end{center}
% \end{frame}

% \begin{frame}{Experimental Setup}

%   \begin{itemize}
%   \item Two datasets, E2E challenge and WikiBio
%     \air
%   \item Training with 35 and 65 state models, each 1x300 LSTMs.
%     \air
%   \item Extract 100 most common templates for each.
%     \air
%   \item Vocabulary limited to non-copy-able words.
%     \air

%   \item Generation with beam search with a pre-selected template.
%   \end{itemize}
% \end{frame}




% \begin{frame}{WikiBio (500k)}

%   \begin{center}



%       \begin{figure}[t]
% \centering
% \begin{tabular}{@{}l@{}}
% \toprule
% \\
% % \begin{tabular}[c]{c}
% %   \hspace{2.5cm}
% %     % \includegraphics[scale=0.7]{wbpage_cropped.pdf}
% % \end{tabular}
% \midrule
% \begin{tabular}[c]{@{}l@{}}
% {\small Frederick Parker-Rhodes (21 March 1914 - 21 November} \\
% {\small 1987) was an English linguist, plant pathologist, computer} \\
% {\small scientist, mathematician, mystic, and mycologist.}
% \end{tabular} \\
% \bottomrule
% \end{tabular}
% % \caption{An example from the WikiBio dataset~\citep{lebret2016neural} for entity \texttt{Frederick Parker-Rhodes}; $x$ (top) and $y$ (bottom) is the corresponding reference generation.}
% \label{fig:wbex}
% \end{figure}

%   \end{center}
% \end{frame}






% \begin{frame}{WikiBio}
% \begin{table}[t!]
% \small
% \centering
% \begin{tabular}{@{}lccc@{}}
% \toprule
%  & BLEU & NIST & ROUGE-4\\
% \midrule
% Conditional KN-LM  & 19.8 & 5.19 & 10.7 \\
% NNLM (field)  & 33.4 & 7.52 & 23.9 \\
% NNLM (field \& word)  & 34.7 & 7.98 & 25.8 \\
% Neural Template &  33.8 & 7.51 & 28.2 \\
% \bottomrule
% \end{tabular}
% \label{tab:wb}
% \end{table}

% \begin{itemize}
% \item Custom KN and NNLM Baselines from LeBret et al (2016)
% \end{itemize}k

% \end{frame}



% \begin{frame}
% \end{frame}


% \begin{frame}{Arguments for Templated Generation}
% Guarantees about the quality, in particular,
% \air


% \begin{itemize}
% \item \textbf{Interpretable} in its factual content.
%   \air


%   \air

% \item \textbf{Controllable} in terms of style.
%   \air


% \end{itemize}

% \end{frame}



\begin{frame}[fragile]{Interpretable Output}

  \begin{center}



  \begin{table}[t]
\small
\centering

\begin{tabular}{@{}l@{}}
  \toprule
  \textbf{kenny warren} \\
  \midrule
  \begin{tabular}[c]{@{}l@{}}
    \textbf{name:} kenny warren, \textbf{birth date:} 1 april 1946, \\
    \textbf{birth name:} kenneth warren deutscher, \textbf{birth place:} brooklyn, new york, \\ \textbf{occupation:} ventriloquist, comedian, author, \\
    \textbf{notable work:} book - the revival of ventriloquism in america \\
  \end{tabular}         \\
  \midrule

  \begin{tabular}[c]{@{}l@{}}
    1. \colorbox{green}{kenny warren deutscher} (\colorbox{pink}{april 1, 1946}) is an \colorbox{cyan}{american} ventriloquist. \\
    2. \colorbox{green}{kenny warren deutscher} (\colorbox{pink}{april 1, 1946}, brooklyn,) is an \colorbox{cyan}{american} ventriloquist.\\
    3. \colorbox{green}{kenny warren deutscher} (\colorbox{pink}{april 1, 1946}) is an \colorbox{cyan}{american} \\
    \hspace{1cm} ventriloquist, best known for his the revival of ventriloquism. \\
    4. \colorbox{yellow}{``kenny'' warren} is an \colorbox{cyan}{american} ventriloquist. \\
5. kenneth warren \colorbox{yellow}{``kenny'' warren} (born \colorbox{pink}{april 1, 1946}) is  an \colorbox{cyan}{american} ventriloquist, and author. \\
\end{tabular} \\
\bottomrule
\end{tabular}
\label{tab:wbcontrol}
\end{table}

  \end{center}
\end{frame}


\begin{frame}{Controllable Style}

  \begin{table}[t]
\small
\centering
\begin{tabular}{@{}l@{}}
\toprule
\textbf{The Golden Palace} \\
\midrule
\begin{tabular}[c]{@{}l@{}}
name[The Golden Palace], type[coffee shop], food[Chinese], \\
priceRange[cheap] custRating[5 out of 5], area[city centre], \\
\end{tabular}         \\
\midrule
\begin{tabular}[c]{@{}l@{}}
1. The Golden Palace is a coffee shop located in the city centre. \\
2. In the city centre is a cheap Chinese coffee shop called  The Golden Palace. \\
3. The Golden Palace is a Chinese coffee shop. \\
4. The Golden Palace is a Chinese coffee shop  with a customer rating of 5 out of 5. \\
5. The Golden Palace that serves Chinese food in the cheap \\
\; \; price range. It is located in the city centre.  Its customer rating is 5 out of 5. \\

\end{tabular} \\
\bottomrule
\end{tabular}
% \caption{Impact of varying the template $z^{(i)}$ for a single $x$ from the E2E dataset.}
\label{tab:e2econtrol}
\end{table}
\end{frame}


{
\setbeamercolor{background canvas}{bg=}
\includepdf[pages=27-30]{template}
}




% \begin{frame}{Automatic Metrics}
% \begin{table}[t!]
% \small
% \centering

%   \begin{tabular}{lc}
%     \toprule
%     &   \\
%     \midrule
%      & \multicolumn{1}{c}{Reviews (ROUGE)} \\
%     \midrule
%     Template & 54.6 \\
%     % Beam Search Optimization     & 33.2 & 34.3 \\
%     Neural Template  &  65.0 \\
%     Best Model & 68.5   \\
%     \midrule

%     \midrule
%     & \multicolumn{1}{c}{WikiBio (BLEU) } \\
%     % &  $K_e$ = 1 & $K_e$ = 5 & $K_e$ = 10 \\
%     \midrule

%     Template &  19.8 \\
%     % Beam Search Optimization     & 33.2 & 34.3 \\
%     Neural Template  & 34.7  \\
%     Best Model &  34.8\\
%     \bottomrule
%   \end{tabular}

% % \includegraphics[width=10cm]{crop1}
% % \air

% % \textbf{WikiBio}
% % \air

% % \includegraphics[width=8cm]{crop2}
% % % \caption{Comparison of the system of \citet{duvsek2016sequence}, which forms the baseline for the E2E challenge, a non-parametric, substitution-based baseline (see text), and our HSMM model on the validation and test portions of the E2E dataset. ``ROUGE'' is ROUGE-L. Models are evaluated using the official E2E NLG Challenge scoring scripts.}
% % \label{tab:e2e}
% \end{table}
% \end{frame}
